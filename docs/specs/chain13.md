# Chain13 Developer Documentation

## Overview
" Advanced chain composition demonstrating multi-stage processing pipelines
" Comparison between local Ollama (chain13.js) and Google GenAI (chain13g.js) implementations
" Data transformation between chain stages using lambda functions

## Key Features
" **Multi-Stage Processing**: Four-stage pipeline with intermediate data transformation
" **Model Comparison**: Identical logic on local vs cloud AI models
" **Data Flow Transformation**: Lambda function converts response content to template variables
" **Composed Chains**: RunnableSequence combining multiple processing stages

## Architecture Components

### Local Implementation (chain13.js)
" **ChatOllama**: Local AI model (gemma3:4b-it-qat)
" **Local Processing**: No API keys or external dependencies
" **Temperature**: 0 (deterministic responses)
" **Base URL**: Default localhost:11434

### Cloud Implementation (chain13g.js)
" **ChatGoogleGenerativeAI**: Google Gemini 1.5 Flash
" **API Integration**: Requires GOOGLE_API_KEY environment variable
" **External Processing**: Cloud-based AI computation
" **dotenv**: Environment variable management

## Pipeline Architecture

### Stage 1: Initial Chain
```javascript
const chain = template.pipe(model);
// Input: {pet_animal: "Panda"}
// Output: AI response with 3 nickname suggestions
```

### Stage 2: Data Transformation
```javascript
(input) => ({pet_names : input.content})
// Converts AI response content to template variable format
```

### Stage 3: Second Template
```javascript
template2.pipe(model)
// Uses transformed data for follow-up question
```

### Stage 4: Final Processing
" Model processes refined query about dog name suitability
" Returns final recommendation based on initial suggestions

## Composed Chain Structure
```javascript
const composedChain = RunnableSequence.from([
    chain,                                    // Generate nicknames
    (input) => ({pet_names : input.content}), // Transform data
    template2,                                // Process transformed data
    model                                     // Generate final response
]);
```

## Template System

### Template 1: Nickname Generation
" **Purpose**: Generate initial nickname suggestions
" **Format**: "Suggest 3 nicknames for a {pet_animal}"
" **Variable**: pet_animal (input animal type)

### Template 2: Name Evaluation
" **Purpose**: Evaluate nickname suitability for dogs
" **Format**: "Which of these {pet_names} is also a good pet name for a dog"
" **Variable**: pet_names (from previous stage output)

## Data Transformation Logic
" **Input Processing**: Takes AI response object with content property
" **Variable Mapping**: Extracts content and maps to new template variable
" **Format Conversion**: Converts response content to template-compatible format
" **Chain Continuity**: Ensures data flows correctly between stages

## Model Comparison

### Local vs Cloud Processing
" **Performance**: Local processing depends on hardware; cloud has network latency
" **Cost**: Local is free after setup; cloud charges per token
" **Privacy**: Local keeps data on-premises; cloud sends to external service
" **Availability**: Local requires Ollama service; cloud needs internet connection

### Implementation Differences
" **Environment Setup**: Ollama vs Google API key configuration
" **Import Statements**: Different model imports and dotenv handling
" **Model Configuration**: Different parameter sets and authentication

## Use Cases
" **Multi-Step AI Reasoning**: Complex decision-making processes
" **Data Refinement**: Progressive improvement of AI responses
" **Contextual Processing**: Using previous outputs to inform subsequent queries
" **Comparative Analysis**: Evaluating options generated by AI

## Example Data Flow
1. **Input**: `{pet_animal: "Panda"}`
2. **Stage 1 Output**: "Bamboo, Po, Patches" (AI-generated nicknames)
3. **Transformation**: `{pet_names: "Bamboo, Po, Patches"}`
4. **Final Output**: AI evaluation of which names work well for dogs

## Developer Benefits
" **Modular Design**: Each stage can be tested and modified independently
" **Reusable Components**: Templates and transformations can be reused
" **Flexible Architecture**: Easy to add/remove processing stages
" **Model Agnostic**: Same logic works with different AI providers

## Configuration Options
" **Model Selection**: Switch between local and cloud models
" **Temperature Settings**: Adjust randomness in AI responses
" **Chain Length**: Add or remove processing stages
" **Transformation Logic**: Customize data transformation between stages

## Error Handling Considerations
" **Chain Failures**: Any stage failure breaks the entire pipeline
" **Data Format**: Ensure transformation functions handle various response formats
" **Model Availability**: Verify model service is running (local) or accessible (cloud)
" **Variable Validation**: Check that transformed data matches template expectations

## Performance Characteristics
" **Sequential Processing**: Each stage waits for previous completion
" **Memory Usage**: Intermediate results stored during pipeline execution
" **Latency**: Total time is sum of all stage processing times
" **Throughput**: Limited by slowest stage in the pipeline

## Best Practices
" **Error Boundaries**: Implement try-catch around each pipeline stage
" **Data Validation**: Verify data format between transformations
" **Logging**: Add logging to understand pipeline data flow
" **Testing**: Test each stage independently before composition
" **Documentation**: Document expected input/output for each stage